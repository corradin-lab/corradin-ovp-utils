{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Found ID column, setting index. This might take a bit long. Please be patient.\n"
     ]
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from functools import partial, partialmethod\n",
    "from toolz import curry\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import settings\n",
    "from Field import Field\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from dataclasses import replace as dc_replace\n",
    "from typing import Union, Dict, ClassVar\n",
    "from multipledispatch import dispatch\n",
    "from inspect import isclass\n",
    "\n",
    "\n",
    "def pass_func(self, val):\n",
    "    pass\n",
    "\n",
    "\n",
    "func_property = partial(property, fset= pass_func )\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FieldSet():\n",
    "    name: str = field(compare=False)\n",
    "    field_class: ClassVar = Field #field(repr=False)\n",
    "\n",
    "    #what will be shown to the user\n",
    "    field_names: list = field(init=False,compare=False) #field(property(lambda self: list(self._fields.keys()), fset=lambda self,x: None))\n",
    "    filter_names: list = field(init=False,compare=False)\n",
    "\n",
    "    #underlying data\n",
    "    fields: Dict[str,Field] = field(repr=False, default_factory=dict)\n",
    "    filters: dict = field(repr=False, default_factory=dict)\n",
    "\n",
    "    @func_property\n",
    "    def field_names(self):\n",
    "        return list(self.fields.keys())\n",
    "\n",
    "    @func_property\n",
    "    def filter_names(self):\n",
    "        return list(self.filters.keys())\n",
    "\n",
    "#     @property\n",
    "#     def fields(self):\n",
    "#         return list(self._fields.keys())\n",
    "\n",
    "#     @fields.setter\n",
    "#     def fields(self, call):\n",
    "#         pass\n",
    "\n",
    "\n",
    "    def add_fields(self,dict_or_list,*, overwrite=False, name: str=None, arrays=None, instances=None):\n",
    "        field_dict = FieldSet.make_fields_dict(dict_or_list, array_list=arrays, instance_list=instances)\n",
    "        overlap_keys = set(field_dict.keys()) & set(self.fields)\n",
    "        is_overlap = len(overlap_keys) != 0\n",
    "        if is_overlap and not overwrite:\n",
    "            raise ValueError(f\"The following field name(s): {overlap_keys} is already in the set, remove field(s) or set overwrite=True to update old fields with new ones\")\n",
    "        \n",
    "        #return a new copy of the FieldSet instance with the attribute changed\n",
    "        if name is None :\n",
    "            return dc_replace(self,fields = {**self.fields, **field_dict})\n",
    "        else:\n",
    "            return dc_replace(self,fields = {**self.fields, **field_dict}, name=name)\n",
    "    \n",
    "    def rename_fields(self, rename_dict: Dict[str,str]):\n",
    "        old_dict = self.fields\n",
    "        new_dict = {(key if key not in rename_dict else rename_dict[key]): (value if key not in rename_dict else value.rename(rename_dict[key])) for key, value in old_dict.items()}\n",
    "        return dc_replace(self, fields = new_dict)\n",
    "    \n",
    "    \n",
    "    @func_property\n",
    "    def ddf(self):\n",
    "        if not self.fields:\n",
    "            raise ValueError(\"No fields in FieldSet\")\n",
    "        return dd.concat([field.all_cols_df for field in self.fields.values()], join=\"inner\", axis=1)\n",
    "    \n",
    "    \n",
    "    def get_field_cols(self, request_fields: Union[list,str]) -> np.ndarray:\n",
    "        valid_fields = [field in self.fields for field in request_fields]\n",
    "        \n",
    "        if not all(valid_fields):\n",
    "            raise ValueError(\"invalid field(s) detected\")\n",
    "        \n",
    "        field_obj_list = [self.fields[field] for field in request_fields]\n",
    "        list_of_col_lists = [field_obj.all_cols_df.columns for field_obj in field_obj_list]\n",
    "\n",
    "        #flatten list\n",
    "        all_cols = np.concatenate(list_of_col_lists)\n",
    "        \n",
    "        return all_cols\n",
    "        \n",
    "        \n",
    "    \n",
    "    #def add_filter(self,field_name)\n",
    "    def eval_filter(self,expr):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def modify_dict_item(dict_value, array_list=None, instance_list=None):\n",
    "        # ex: {\"pheno\": dict_value, \"arrays\": array_list, \"instances\": instance_list}\n",
    "        if isinstance(dict_value, dict):\n",
    "            return {**dict_value, **{\"arrays\": array_list, \"instances\": instance_list}}\n",
    "        \n",
    "        # ex: \"Monocyte count\"\n",
    "        if isinstance(dict_value, str):\n",
    "            return {\"pheno\": dict_value, \"arrays\": array_list, \"instances\": instance_list}\n",
    "        \n",
    "        raise ValueError(\"Must be dict or str\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def modify_dict(data_dict, array_list=None, instance_list=None):\n",
    "        new_dict = {key: FieldSet.modify_dict_item(value, array_list, instance_list) for key, value in data_dict.items()}\n",
    "        return new_dict\n",
    "        \n",
    "    @staticmethod\n",
    "    def make_fields_dict(data: Dict[str,Union[str,int,Field]], array_list=None, instance_list=None):\n",
    "        \"\"\"\n",
    "        parameters:\n",
    "        * data: can be\n",
    "            - single Field \n",
    "            - list of Fields\n",
    "            - dict of {field_name: field_args_dict} to automatically generate Field objects\n",
    "        *returns:\n",
    "            a dict of {name: Field_object}\n",
    "        \"\"\"\n",
    "        \n",
    "        #dict of name: [Field/FieldID]\n",
    "        if isinstance(data, dict):\n",
    "            modified_data = FieldSet.modify_dict(data, array_list=array_list, instance_list= instance_list)\n",
    "            return Field.make_fields_dict(modified_data) #{name: (value if isinstance(value, FieldSet.field_class) else Field.init_multi_type(value, name=name)) for name, value in data.items()}\n",
    "        \n",
    "        #list of fields\n",
    "        if isinstance(data,list):\n",
    "            if all((isinstance(ele,FieldSet.field_class) for ele in data)):\n",
    "                return {field.name:field for field in data}\n",
    "        \n",
    "        if isinstance(data, FieldSet.field_class):\n",
    "            return {data.name: data}\n",
    "        \n",
    "        raise TypeError(f\"Can only accept list of {FieldSet.field_class} or Dictionary \\{name: Field/FieldID \\}\") \n",
    "\n",
    "    \n",
    "#return FieldSet\n",
    "\n",
    "#PhenoField = partialclass(PhenoField, data_dict = data_dict, pheno_df = pheno_df, coding_file_path_template=coding_file_path_template)\n",
    "#FieldSet = partialclass(FieldSet,field_class= Field)        \n",
    "\n",
    "test_set = FieldSet(\"test_set\")\n",
    "test_set"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "bgen",
   "language": "python",
   "name": "bgen"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
