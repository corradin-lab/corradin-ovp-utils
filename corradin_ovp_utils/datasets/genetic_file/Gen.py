# AUTOGENERATED! DO NOT EDIT! File to edit: 01_datasets_gen_file_format.ipynb (unless otherwise specified).

__all__ = ['GenFileFormat', 'create_file_object_class']

# Cell
from . import GeneticFileFormat, triplicate_converter, get_possible_geno_combinations
from typing import Any, Dict, List, Optional, Literal, Union, Protocol
from enum import Enum
import numpy as np
from kedro.io import AbstractVersionedDataSet
from pydantic import BaseModel
from pathlib import Path, PosixPath
from pydantic.dataclasses import dataclass
from dataclasses import InitVar, asdict
from copy import deepcopy
import fsspec
from kedro.io.core import (
    AbstractVersionedDataSet,
    DataSetError,
    Version,
    get_filepath_str,
    get_protocol_and_path,
)
from kedro.extras.datasets.pandas import CSVDataSet
from fastcore.meta import delegates
from fastcore.basics import basic_repr
from functools import partial, wraps, lru_cache
from types import SimpleNamespace
from tqdm.auto import tqdm
import pandas as pd
import itertools
from boltons.strutils import bytes2human
#from dask import delayed
# import dask.dataframe as dd
# import vaex
# import modin.pandas as mpd
#from dask.distributed import Client

# Cell

class GenFileFormat(GeneticFileFormat):
    prob_n_cols: int
    initial_cols: List[str]
    rsid_col: str
    alleleA_col: str
    alleleB_col: str
    ref_alt_delim: Optional[str]
    pandas_args: Dict[str, Any]
    current_file_path: Optional[str]

    # check that num_cols - initial cols is divisible by prob_n_cols
    # if ref col == alt col then ref_alt_delim needs to be specified, so ref,alt = ref_col.str.split(delim)

    def col_name_generator(self, include_initial_cols=True):

        if include_initial_cols:
            for col in self.initial_cols:
                yield (col, "")

        if self.sample_ids is None:
            sample_ids_gen = (f"sample{i}" for i in itertools.count(1))
        else:
            sample_ids_gen = (sample_id for sample_id in self.sample_ids)

        while True:
            cur_sample_id = next(sample_ids_gen)
            #for allele_prob_col_num in range(1, self.prob_n_cols + 1):
            yield (f"{cur_sample_id}", "AA")
            yield (f"{cur_sample_id}", "AB")
            yield (f"{cur_sample_id}", "BB")

    @property
    def gen_info_cols(self):
        return [self.rsid_col, self.ref_col, self.alt_col]

    @property
    def column_headers(self):
        #read the first non-header line
        first_line_df = next(self._load_unprocessed(chunksize=1))
        generator = self.col_name_generator()
        col_index = pd.MultiIndex.from_tuples([next(generator) for col in first_line_df.columns], names = ["first", "second"])
        return col_index

    @property
    def sample_cols(self):
        cols = [col for col in self.column_headers if col not in set(self.initial_cols)]
        return cols

    @property
    def _sample_list(self):
        if self.sample_ids is not None:
            return list(self.sample_ids)
        else:
            return [f"sample{i}" for i in range(1, self.num_samples + 1)] #list(set([col.split("_")[0] for col in self.sample_cols]))

    @property
    def num_samples(self):
        return int(len(self.sample_cols)/self.prob_n_cols)

    @property
    def load_args(self):
        load_args = deepcopy(self.pandas_args)
        load_args["names"] = self.column_headers
        return load_args

    @delegates(pd.read_csv)
    def _load_unprocessed(self, **kwargs):
        return pd.read_csv(filepath_or_buffer = self.current_file_path, **self.pandas_args, **kwargs)

    def get_rsid_col(self, chrom =None, **kwargs):
        kwargs_modified = kwargs.copy()
        kwargs_modified["chunksize"] = None
        rsid_col = self._load(chrom = chrom, usecols = [self.rsid_col], **kwargs_modified)
        rsid_col = rsid_col.query("rsid.str.startswith('r')")
        return rsid_col

#     def _load(self, chrom = None, **kwargs):
#         # use another attribute so `load` and `_load_unprocessed` can share
#         self.current_file_path = self.get_resolved_file_path(chrom)
#         load_args = self.load_args
#         df = pd.read_csv(self.current_file_path, **load_args, **kwargs)
#         return df


    def load_single_chrom_file(self, chrom, **kwargs):
        if chrom == self.file_path.chrom_num:
            return self.load_split_by_chromosome(chrom=chrom, **kwargs)
        else:
            return None

    def load_split_by_chromosome(self, chrom, **kwargs):
        resolved_file_path = self.get_resolved_file_path(chrom)
        if not resolved_file_path.is_file():
            print(f"Cannot find file {resolved_file_path.as_posix()}")
            return None

        self.current_file_path = self.get_resolved_file_path(chrom)
        sample_cols = self.sample_cols
        sample_list = self._sample_list
        TemplatedGenFileObject = create_file_object_class(self.prob_n_cols, self.rsid_col, alleleA_col= self.alleleA_col, alleleB_col= self.alleleB_col, load_args = self.load_args)
        TemplatedGenFileObject.__repr__ = basic_repr("chrom,file_path")
        #gen_file_object = GenFileObject(df = df, rsid_col = rsid_col, sample_cols = sample_cols, sample_list = sample_list, file_path = self.current_file_path)
        gen_file_object = TemplatedGenFileObject(chrom = chrom,
                                                 sample_cols = sample_cols,
                                                 sample_list = sample_list,
                                                 column_headers= self.column_headers,
                                                 file_path = self.current_file_path)
        return gen_file_object

    def load(self, chrom=None, **kwargs):
        if self.is_chrom_template():
            return self.load_split_by_chromosome(chrom = chrom, **kwargs)
        else:
            return self.load_single_chrom_file(chrom = chrom, **kwargs)

    def load_all_chrom(self):
        return {chrom: self.load(chrom) for chrom in range(1,23)}


    def get_geno_each_sample(self, rsid_dict:Dict[int, List[str]], id_col_list: List[str], batch_size=1_000, excluded_sample_ids: List[str] =[]):
        all_chrom_dict = self.load_all_chrom()
        all_samples_geno_df, all_geno_df = zip(*[all_chrom_dict[chrom].get_geno_each_sample(rsid_list = rsid_list, id_col_list= id_col_list, excluded_sample_ids= excluded_sample_ids) for chrom, rsid_list in rsid_dict.items()])
        return pd.concat(all_samples_geno_df), pd.concat(all_geno_df)



    @delegates(pd.read_csv)
    def get_rsid_df(self,chrom=None, rsid_list=None, **kwargs):
        rsid_df = self.load(chrom = chrom, chunksize=100_000)
        if rsid_list is not None:
            query = f"{self.rsid_col} in {rsid_list}"
            found_rsid_df = rsid_df.query(query)

        else:
            found_rsid_df = rsid_df


#         found_index = found_rsid_df.index
#         found_rsids = set(found_rsid_df[self.rsid_col].unique())
#         found_rsid_df_full = self.load(chrom= chrom, skiprows = lambda x: x not in found_index, **kwargs)

        return found_rsid_df

    @delegates(load)
    def get_genotypes_df(self, chrom=None, rsid_list: List = None, **kwargs):
        if rsid_list is not None:
            geno_df = self.get_rsid_df(chrom=chrom, rsid_list = rsid_list, usecols = self.gen_info_cols, **kwargs)
        else:
            geno_df = self.load(chrom = chrom, usecols = self.gen_info_cols,**kwargs)
        geno_df["homo_ref"] = geno_df.loc[:,[self.ref_col]] *2
        make_het_geno_func = lambda row: ''.join(sorted([row[self.ref_col],
                                   row[self.alt_col]]))
        geno_df["het"] = geno_df[[self.ref_col, self.alt_col]].apply(make_het_geno_func, axis=1)
        geno_df["homo_alt"] = geno_df.loc[:,self.alt_col] *2

        geno_df = geno_df.set_index(self.rsid_col)
        return geno_df


    @delegates(pd.read_csv)
    def get_rsid_df_big(self, chrom=None, rsid_list= None, **kwargs):
        rsid_col = self.load(chrom=chrom, usecols = [self.rsid_col])
        rsid_col = rsid_list.query("rsid.str.startswith('r')")
        found_rsids = rsid_col.query("rsid in @test_list")

        def create_found_rsid_df_generator():
            found_rsid_df_generator = self.load(chrom = chrom, skiprows= lambda x : x not in set(test_result.index), chunksize = 10, index_col = self.rsid_col)
            return found_rsid_df_generator

        return create_found_rsid_df_generator()

    def sample_columns_iter_list(rsid_df):
        for sample in self._sample_list:
            sample_cols = [f"{sample}_{allele_prob_col_num}" for allele_prob_col_num in range(1, self.prob_n_cols + 1)]
            sample_cols_df = rsid_df[sample_cols]
            yield SimpleNamespace(sample_id = sample,
                                  sample_df = sample_cols_df)



    def get_genotypes_df_big(self, chrom=None, ):
        for rsid_df in found_rsid_df_generator:
            geno_df = get_possible_geno_combinations(rsid_df, big_gen_file.ref_col, big_gen_file.alt_col)
            yield geno_df

#     def sample_columns_iter(self, chrom=None, rsid_list=None, **kwargs):

#         df = self.get_rsid_df(chrom=chrom, rsid_list = rsid_list, **kwargs)
#         df = df.set_index(self.rsid_col)

#         for sample in self._sample_list:
#             sample_cols = [f"{sample}_{allele_prob_col_num}" for allele_prob_col_num in range(1, self.prob_n_cols + 1)]
#             sample_cols_df = df[sample_cols]
#             yield SimpleNamespace(sample_id = sample,
#                                   sample_df = sample_cols_df)

#     def sample_columns_iter(


    #the function has to accept sample_id kwarg
    def apply_func_to_all_samples(self, func, rsid_list=None, chrom=None, **kwargs):
        result_dict = [func(sample_obj.sample_df, sample_id = sample_obj.sample_id, **kwargs) for sample_obj in tqdm(self.sample_columns_iter(chrom= chrom, rsid_list=rsid_list))]#{sample_obj.sample_id: func(sample_obj.sample_df, sample_id = sample_obj.sample_id, **kwargs) for sample_obj in tqdm(self.sample_columns_iter(rsid_list=rsid_list))}
        result_df = pd.concat(result_dict, axis=1)
        #, orient="records")
        return result_df

#     def get_geno_each_sample(self, *, chrom=None, rsid_list:List[str]):
#         geno_each_sample_df = self.apply_func_to_all_samples(triplicate_converter,
#                                         rsid_list = rsid_list,
#                                         genotype_df = self.get_genotypes_df(chrom=chrom, rsid_list = rsid_list),
#                                         chrom=chrom)
#         return geno_each_sample_df.T

#     @property
#     def single_line_iter(self, **runtime_kwargs):
#         return pd.read_csv(self.filepath,
#                            **self.load_args,
#                            **runtime_kwargs,
#                            chunksize=1)

#     #@delegates(pd.read_csv, but= list(self.load_args.keys()))
#     def load_full(self, **kwargs):
#         return pd.read_csv(self.filepath,
#                            **self.load_args,
#                           **kwargs)

#     #if ref_col = alt_col then ref_alt_delim need to be specified

def create_file_object_class(prob_n_cols, rsid_col, alleleA_col, alleleB_col, load_args):
    class GenFileObject(BaseModel):
        chrom: int
        file_path: Path
        #rsid_col: Any
        sample_cols: List
        sample_list: List
        column_headers: pd.MultiIndex

        class Config:
            arbitrary_types_allowed = True

        @delegates(pd.read_csv, but="names")
        def load_df(self, size_limit = 1_000_000_000, **kwargs): # default limit is 1 GB
            file_size = self.file_path.stat().st_size
            if file_size > size_limit:
                raise MemoryError(f"the file's size ({bytes2human(file_size)}) is too big, input limit is {bytes2human(size_limit)}.\n Please increase the limit or choose a smaller file")
            else:
                df = pd.read_csv(self.file_path, **load_args, **kwargs)
            return df

        def sample_columns_iter_list(self, rsid_df: pd.DataFrame, excluded_sample_ids: List[str] =[]):
            excluded_sample_ids_set = set(excluded_sample_ids)
            for sample in self.sample_list:
                if sample in excluded_sample_ids_set:
                    continue
                else:
                    #sample_cols = [f"{sample}_{allele_prob_col_num}" for allele_prob_col_num in range(1, prob_n_cols + 1)]
                    sample_cols_df = rsid_df[sample]
                    yield SimpleNamespace(sample_id = sample,
                                          sample_df = sample_cols_df)


        def get_geno_each_sample(self, rsid_list: List[int], id_col_list: List[str], batch_size=1_000, excluded_sample_ids: List[str] =[]):
            found_lines = []
            first_level_index = self.column_headers.get_level_values("first")
            id_col_index_list = [first_level_index.get_loc(id_col) for id_col in id_col_list]
            all_samples_df_partials = []
            all_geno_df_partials = []
            query_rsid_set = set(rsid_list)

            print(f"reading genetic file and collecting found SNPs for file {self.file_path.as_posix()}")

            with open(self.file_path, "r") as file:
                for i,line in tqdm(enumerate(file)):
                    line_list = line.strip().split(" ")
                    for index in id_col_index_list:
                        if line_list[index] in query_rsid_set:
                            line_list.append(line_list[index])
                            found_lines.append(line_list)


                    if len(found_lines) >= batch_size:
                        print("processing batch")
                        all_samples_df_partial, geno_df_partial = self._process_found_lines(found_lines, excluded_sample_ids= excluded_sample_ids)
                        all_samples_df_partials.append(all_samples_df_partial)
                        all_geno_df_partials.append(geno_df_partial)
                        found_lines = []

            print("processing last batch")
            if len(found_lines) > 0:
                all_samples_df_partial, geno_df_partial = self._process_found_lines(found_lines, excluded_sample_ids= excluded_sample_ids)
                all_samples_df_partials.append(all_samples_df_partial)
                all_geno_df_partials.append(geno_df_partial)

            all_samples_df = pd.concat(all_samples_df_partials, axis = 1)
            all_geno_df = pd.concat(all_geno_df_partials)
            return all_samples_df, all_geno_df


        def _process_found_lines(self, found_lines, excluded_sample_ids):
            combined_lines = pd.DataFrame.from_records(found_lines, columns = self.column_headers.append(pd.MultiIndex.from_tuples([("id_col", "")])))
            combined_lines = combined_lines.set_index("id_col")
            geno_df = get_possible_geno_combinations(combined_lines, alleleA_col, alleleB_col)
            all_samples_df = [triplicate_converter(sample.sample_df, genotype_df= geno_df, sample_id = sample.sample_id) for sample in tqdm(self.sample_columns_iter_list(combined_lines, excluded_sample_ids))]
            all_samples_df = pd.concat(all_samples_df, axis=1)
            all_samples_df = all_samples_df.T
            return all_samples_df, geno_df

    return GenFileObject
